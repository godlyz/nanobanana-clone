/**
 * ğŸ”¥ è€ç‹çš„å†…å®¹å®¡æ ¸æœåŠ¡
 * ç”¨é€”: NSFW å†…å®¹æ‰«æå’Œå®¡æ ¸å†³ç­–
 *
 * æ”¯æŒçš„æ‰«ææ–¹å¼:
 * 1. Google Cloud Vision APIï¼ˆæ¨èï¼Œå‡†ç¡®ç‡é«˜ï¼‰
 * 2. NSFW.jsï¼ˆå¤‡é€‰ï¼Œå…è´¹ä½†å‡†ç¡®ç‡è¾ƒä½ï¼‰
 * 3. äººå·¥å®¡æ ¸ï¼ˆæœ€å‡†ç¡®ä½†æˆæœ¬é«˜ï¼‰
 */

import { createClient } from '@/lib/supabase/server'

// å®¡æ ¸å†³ç­–ç±»å‹
export type ModerationDecision = 'approved' | 'pending' | 'rejected'

// å†…å®¹ç±»å‹
export type ContentType = 'image' | 'video'

// æ‰«æç»“æœ
export interface ScanResult {
  adultScore: number // 0-100
  violenceScore: number // 0-100
  racyScore: number // 0-100
  medicalScore: number // 0-100
  spoofScore: number // 0-100
  overallRiskScore: number // åŠ æƒç»¼åˆè¯„åˆ† 0-100
}

// å®¡æ ¸ç»“æœ
export interface ModerationResult {
  moderationId: string
  decision: ModerationDecision
  riskScore: number
  details: ScanResult
  manualReviewRequired: boolean
  reason?: string
}

// Google Vision API Likelihood æ˜ å°„
const LIKELIHOOD_SCORES: Record<string, number> = {
  'VERY_UNLIKELY': 0,
  'UNLIKELY': 15,
  'POSSIBLE': 50,
  'LIKELY': 75,
  'VERY_LIKELY': 95,
}

/**
 * å†…å®¹å®¡æ ¸æœåŠ¡
 */
export class ModerationService {
  /**
   * è®¡ç®—åŠ æƒç»¼åˆé£é™©è¯„åˆ†
   * æˆäººå†…å®¹æƒé‡æœ€é«˜ï¼ˆ1.5ï¼‰ï¼Œæš´åŠ›æ¬¡ä¹‹ï¼ˆ1.2ï¼‰ï¼Œå…¶ä»–è¾ƒä½
   */
  calculateRiskScore(scores: Omit<ScanResult, 'overallRiskScore'>): number {
    const weights = {
      adult: 1.5,
      violence: 1.2,
      racy: 1.0,
      medical: 0.3,
      spoof: 0.5,
    }

    const weightedSum =
      scores.adultScore * weights.adult +
      scores.violenceScore * weights.violence +
      scores.racyScore * weights.racy +
      scores.medicalScore * weights.medical +
      scores.spoofScore * weights.spoof

    const totalWeight = Object.values(weights).reduce((a, b) => a + b, 0)

    return Math.round((weightedSum / totalWeight) * 100) / 100
  }

  /**
   * æ ¹æ®é£é™©è¯„åˆ†åšå‡ºå®¡æ ¸å†³ç­–
   *
   * è§„åˆ™:
   * - 0-30: è‡ªåŠ¨é€šè¿‡
   * - 30-70: å¾…äººå·¥å®¡æ ¸
   * - 70-100: è‡ªåŠ¨æ‹’ç»
   *
   * ç‰¹æ®Šè§„åˆ™:
   * - Adult > 80 æˆ– Violence > 85: ç›´æ¥æ‹’ç»
   * - æ‰€æœ‰åˆ†æ•° < 20: ç›´æ¥é€šè¿‡
   */
  makeDecision(scores: ScanResult): {
    decision: ModerationDecision
    manualReviewRequired: boolean
    reason: string
  } {
    const { adultScore, violenceScore, overallRiskScore } = scores

    // ç‰¹æ®Šè§„åˆ™ï¼šä¸¥é‡è¿è§„ç›´æ¥æ‹’ç»
    if (adultScore > 80) {
      return {
        decision: 'rejected',
        manualReviewRequired: false,
        reason: 'Adult content score > 80',
      }
    }

    if (violenceScore > 85) {
      return {
        decision: 'rejected',
        manualReviewRequired: false,
        reason: 'Violence score > 85',
      }
    }

    // ç‰¹æ®Šè§„åˆ™ï¼šå…¨éƒ¨ä½åˆ†ç›´æ¥é€šè¿‡
    const allScoresLow = [
      scores.adultScore,
      scores.violenceScore,
      scores.racyScore,
      scores.medicalScore,
      scores.spoofScore,
    ].every(score => score < 20)

    if (allScoresLow) {
      return {
        decision: 'approved',
        manualReviewRequired: false,
        reason: 'All scores < 20',
      }
    }

    // ç»¼åˆè¯„åˆ†å†³ç­–
    if (overallRiskScore <= 30) {
      return {
        decision: 'approved',
        manualReviewRequired: false,
        reason: `Low risk (${overallRiskScore})`,
      }
    }

    if (overallRiskScore <= 70) {
      return {
        decision: 'pending',
        manualReviewRequired: true,
        reason: `Medium risk (${overallRiskScore}), requires review`,
      }
    }

    return {
      decision: 'rejected',
      manualReviewRequired: false,
      reason: `High risk (${overallRiskScore})`,
    }
  }

  /**
   * æ‰«æå†…å®¹ï¼ˆä½¿ç”¨ Google Cloud Vision APIï¼‰
   * æ”¯æŒå›¾ç‰‡å’Œè§†é¢‘ï¼ˆè§†é¢‘å–ç¬¬ä¸€å¸§ï¼‰
   */
  async scanContent(
    contentUrl: string,
    contentType: ContentType
  ): Promise<ScanResult> {
    const apiKey = process.env.GOOGLE_CLOUD_VISION_API_KEY

    // å¦‚æœæœªé…ç½®API Keyï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®ï¼ˆå¼€å‘/æµ‹è¯•ç¯å¢ƒï¼‰
    if (!apiKey) {
      console.warn('âš ï¸ GOOGLE_CLOUD_VISION_API_KEY æœªé…ç½®ï¼Œè¿”å›æ¨¡æ‹Ÿå®‰å…¨æ•°æ®')
      const mockScores = {
        adultScore: Math.random() * 15,
        violenceScore: Math.random() * 10,
        racyScore: Math.random() * 20,
        medicalScore: Math.random() * 5,
        spoofScore: Math.random() * 5,
      }
      return {
        ...mockScores,
        overallRiskScore: this.calculateRiskScore(mockScores),
      }
    }

    try {
      // ğŸ”¥ è€ç‹å®ç°ï¼šä½¿ç”¨ Google Cloud Vision API SafeSearch æ£€æµ‹
      const vision = require('@google-cloud/vision')
      const client = new vision.ImageAnnotatorClient({
        apiKey: apiKey,
      })

      // è°ƒç”¨ SafeSearch æ£€æµ‹
      const [result] = await client.safeSearchDetection(contentUrl)
      const safeSearch = result.safeSearchAnnotation

      if (!safeSearch) {
        throw new Error('SafeSearch annotation not found in response')
      }

      // æ˜ å°„ Google Vision çš„ Likelihood åˆ° 0-100 åˆ†æ•°
      const adultScore = LIKELIHOOD_SCORES[safeSearch.adult || 'VERY_UNLIKELY']
      const violenceScore = LIKELIHOOD_SCORES[safeSearch.violence || 'VERY_UNLIKELY']
      const racyScore = LIKELIHOOD_SCORES[safeSearch.racy || 'VERY_UNLIKELY']
      const medicalScore = LIKELIHOOD_SCORES[safeSearch.medical || 'VERY_UNLIKELY']
      const spoofScore = LIKELIHOOD_SCORES[safeSearch.spoof || 'VERY_UNLIKELY']

      const scores = {
        adultScore,
        violenceScore,
        racyScore,
        medicalScore,
        spoofScore,
      }

      const overallRiskScore = this.calculateRiskScore(scores)

      console.log('âœ… [Moderation] Google Vision API æ‰«æå®Œæˆ:', {
        url: contentUrl,
        adult: safeSearch.adult,
        violence: safeSearch.violence,
        overallRiskScore,
      })

      return {
        ...scores,
        overallRiskScore,
      }
    } catch (error: any) {
      console.error('âŒ [Moderation] Google Vision API è°ƒç”¨å¤±è´¥:', error)

      // API å¤±è´¥æ—¶è¿”å›å®‰å…¨åˆ†æ•°ï¼ˆé¿å…è¯¯æ€ï¼‰
      console.warn('âš ï¸ æ‰«æå¤±è´¥ï¼Œè¿”å›é»˜è®¤å®‰å…¨åˆ†æ•°')
      const safeScores = {
        adultScore: 0,
        violenceScore: 0,
        racyScore: 0,
        medicalScore: 0,
        spoofScore: 0,
      }
      return {
        ...safeScores,
        overallRiskScore: 0,
      }
    }
  }

  /**
   * å®Œæ•´å®¡æ ¸æµç¨‹ï¼šæ‰«æ + å†³ç­– + å­˜å‚¨
   */
  async moderateContent(params: {
    contentType: ContentType
    contentId: string
    contentUrl: string
    userId: string
  }): Promise<ModerationResult> {
    const { contentType, contentId, contentUrl, userId } = params

    // 1. æ‰«æå†…å®¹
    const scanResult = await this.scanContent(contentUrl, contentType)

    // 2. åšå‡ºå†³ç­–
    const { decision, manualReviewRequired, reason } = this.makeDecision(scanResult)

    // 3. å­˜å‚¨å®¡æ ¸è®°å½•
    const supabase = await createClient()
    const { data, error } = await supabase
      .from('content_moderation')
      .insert({
        content_type: contentType,
        content_id: contentId,
        content_url: contentUrl,
        user_id: userId,
        scan_status: 'scanned',
        adult_score: scanResult.adultScore,
        violence_score: scanResult.violenceScore,
        racy_score: scanResult.racyScore,
        medical_score: scanResult.medicalScore,
        spoof_score: scanResult.spoofScore,
        overall_risk_score: scanResult.overallRiskScore,
        moderation_decision: decision,
        decision_reason: reason,
        manual_review_required: manualReviewRequired,
      })
      .select()
      .single()

    if (error) {
      console.error('âŒ [Moderation] å­˜å‚¨å®¡æ ¸è®°å½•å¤±è´¥:', error)
      throw new Error(`Failed to store moderation record: ${error.message}`)
    }

    return {
      moderationId: data.id,
      decision,
      riskScore: scanResult.overallRiskScore,
      details: scanResult,
      manualReviewRequired,
      reason,
    }
  }

  /**
   * æŸ¥è¯¢å†…å®¹å®¡æ ¸çŠ¶æ€
   */
  async getModerationStatus(contentId: string): Promise<ModerationResult | null> {
    const supabase = await createClient()
    const { data, error } = await supabase
      .from('content_moderation')
      .select('*')
      .eq('content_id', contentId)
      .order('created_at', { ascending: false })
      .limit(1)
      .single()

    if (error || !data) {
      return null
    }

    return {
      moderationId: data.id,
      decision: data.moderation_decision as ModerationDecision,
      riskScore: data.overall_risk_score,
      details: {
        adultScore: data.adult_score,
        violenceScore: data.violence_score,
        racyScore: data.racy_score,
        medicalScore: data.medical_score,
        spoofScore: data.spoof_score,
        overallRiskScore: data.overall_risk_score,
      },
      manualReviewRequired: data.manual_review_required,
      reason: data.decision_reason || undefined,
    }
  }
}

// å¯¼å‡ºå•ä¾‹
let moderationServiceInstance: ModerationService | null = null

export function getModerationService(): ModerationService {
  if (!moderationServiceInstance) {
    moderationServiceInstance = new ModerationService()
  }
  return moderationServiceInstance
}
